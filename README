## Repositories and Original Code

- Original implementation (Sun & Lu attention classifier): 

https://github.com/richardsun-vo/attn_neural_classification_interpret

- Our project repository: 

https://github.com/jpathakbing/ML_ProjectReport

## Team and Contributions

- **Jyotsna Kumari Pathak (@jpathakbing)**  
  Implemented and ran SST and adversarial experiments, created the custom polarity-inverted dataset, performed cross-dataset and polarity-score analysis, and wrote the main project report.

- **Keval Shah (@kshah24bing)**  
  Helped integrate and adapt the original codebase, configured and debugged training runs, contributed to result generation/figures, and assisted with report writing and polishing.

### Important Changes Compared to Original Code

- Added a custom polarity-inverted adversarial dataset and data loading pipeline.  
- Extended training and evaluation scripts for cross-dataset SST ↔ adversarial experiments.  
- Implemented token-level polarity score analysis and consolidated result visualizations for the report.

## Outcomes

- Successfully reproduced the original SST results of Sun & Lu with closely matching accuracy at the reference λ value, validating our implementation.

- Showed that performance on the custom polarity-inverted adversarial dataset drops toward random chance and that SST-trained and adversarial-trained models generalize poorly across datasets, revealing strong reliance on corpus-level token–label statistics rather than robust contextual understanding.

