{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76d2b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'UAFTC'...\n",
      "remote: Enumerating objects: 89, done.\u001b[K\n",
      "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
      "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
      "remote: Total 89 (delta 37), reused 66 (delta 18), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (89/89), 19.24 MiB | 15.93 MiB/s, done.\n",
      "Resolving deltas: 100% (37/37), done.\n",
      "/content/UAFTC/UAFTC/UAFTC/UAFTC\n",
      "appendix_2020.pdf\t\t\t\t      data_processor.py\n",
      "args\t\t\t\t\t\t      derivatives.pdf\n",
      "attention_score_binary_classification.ipynb\t      dynamic_lstm.py\n",
      "attn_model.py\t\t\t\t\t      helper.py\n",
      "attn_neural_classification_interpret_synthetic.ipynb  imgs\n",
      "data\t\t\t\t\t\t      README.md\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/richardsun-voyager/UAFTC.git\n",
    "%cd UAFTC\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0683d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Check GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Create directories\n",
    "!mkdir -p data/custom\n",
    "!mkdir -p results/sst\n",
    "!mkdir -p results/custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916d3285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defined with dropout (p=0.5)\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Attention Classifier Model WITH DROPOUT\n",
    "class AttentionClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, lambda_scale, dropout=0.5):\n",
    "        super(AttentionClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.V = nn.Parameter(torch.randn(embed_dim))  # Context vector\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim))  # Linear layer weight\n",
    "        self.lambda_scale = lambda_scale\n",
    "\n",
    "        # Add dropout layer (as in the paper)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Initialize with uniform distribution [-0.1, 0.1]\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.V, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.W, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "        # x: [batch_size, seq_len]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        # Apply dropout to embeddings (during training)\n",
    "        embeds = self.dropout(embeds)\n",
    "\n",
    "        # Compute attention scores\n",
    "        attention_scores = torch.matmul(embeds, self.V) / self.lambda_scale\n",
    "\n",
    "        # Compute attention weights\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "\n",
    "        # Weighted sum\n",
    "        context = torch.sum(embeds * attention_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "        # Compute polarity score\n",
    "        output = torch.matmul(context, self.W)\n",
    "\n",
    "        if return_attention:\n",
    "            token_polarity = torch.matmul(embeds, self.W)\n",
    "            return output, attention_weights, attention_scores, token_polarity\n",
    "\n",
    "        return output\n",
    "\n",
    "print(\"Model defined with dropout (p=0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c310271",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73c7a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(data, min_freq=1):\n",
    "    \"\"\"Build vocabulary from data\"\"\"\n",
    "    word_counts = Counter()\n",
    "    for text, _ in data:\n",
    "        words = text.split()\n",
    "        word_counts.update(words)\n",
    "\n",
    "    # Use explicit PAD and UNK tokens\n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    idx = 2\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = idx\n",
    "            idx += 1\n",
    "    return vocab\n",
    "\n",
    "def text_to_indices(text, vocab, max_len=50):\n",
    "    \"\"\"Convert text to indices\"\"\"\n",
    "    words = text.split()[:max_len]\n",
    "    indices = [vocab.get(word, vocab['<UNK>']) for word in words]\n",
    "    # Pad to fixed length\n",
    "    while len(indices) < max_len:\n",
    "        indices.append(vocab['<PAD>'])\n",
    "    return indices\n",
    "\n",
    "def train_model(model, train_data, dev_data, vocab, num_epochs, device, verbose=False):\n",
    "    \"\"\"Train the model\"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "    best_dev_acc = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        random.shuffle(train_data)\n",
    "\n",
    "        for text, label in train_data:\n",
    "            indices = text_to_indices(text, vocab)\n",
    "            x = torch.LongTensor([indices]).to(device)\n",
    "            y = torch.FloatTensor([label]).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "\n",
    "            y_scaled = 2 * y - 1\n",
    "            loss = criterion(output * y_scaled, torch.ones_like(output))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pred = (torch.sigmoid(output) > 0.5).float()\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += 1\n",
    "\n",
    "        train_acc = correct / total\n",
    "        dev_acc = evaluate_model(model, dev_data, vocab, device)\n",
    "\n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss/total:.4f}, Train: {train_acc:.4f}, Dev: {dev_acc:.4f}\")\n",
    "\n",
    "        if dev_acc > best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return best_dev_acc\n",
    "\n",
    "def evaluate_model(model, data, vocab, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, label in data:\n",
    "            indices = text_to_indices(text, vocab)\n",
    "            x = torch.LongTensor([indices]).to(device)\n",
    "            y = torch.FloatTensor([label]).to(device)\n",
    "\n",
    "            output = model(x)\n",
    "            pred = (torch.sigmoid(output) > 0.5).float()\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b930e",
   "metadata": {},
   "source": [
    "PART 1: Validate on SST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cade80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SST from pickle files...\n",
      "  Vocabulary: 16174 words\n",
      "  Loading train data...\n",
      "  Loading dev data...\n",
      "  Loading test data...\n",
      "\n",
      "SST Dataset Loaded:\n",
      "  Train: 6920 examples\n",
      "  Dev: 872 examples\n",
      "  Test: 1821 examples\n",
      "\n",
      "Sample examples:\n",
      "  [Positive] rock is destined to be 21st century s new conan and that he s going to...\n",
      "  [Positive] gorgeously elaborate continuation of lord of rings trilogy is so huge ...\n",
      "  [Positive] singer composer bryan adams contributes a slew of songs a few potentia...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_sst_data(data_dir='data/sst'):\n",
    "    \"\"\"Load SST dataset from pickle files\"\"\"\n",
    "\n",
    "    print(\"Loading SST from pickle files...\")\n",
    "\n",
    "    # Load vocabulary - it's a list where vocab[0] contains the words\n",
    "    with open(f'{data_dir}/vocab/local_dict.pkl', 'rb') as f:\n",
    "        vocab_container = pickle.load(f)\n",
    "\n",
    "    # Extract actual vocabulary (first element)\n",
    "    if isinstance(vocab_container, list) and len(vocab_container) > 0:\n",
    "        vocab_list = vocab_container[0]  # The actual word list\n",
    "    else:\n",
    "        vocab_list = vocab_container\n",
    "\n",
    "    # Create index to word mapping\n",
    "    idx2word = {i: word for i, word in enumerate(vocab_list)}\n",
    "    print(f\"  Vocabulary: {len(vocab_list)} words\")\n",
    "\n",
    "    def load_pkl_data(pkl_path):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data_zip = pickle.load(f)\n",
    "\n",
    "        # Convert zip object to list\n",
    "        data = list(data_zip)\n",
    "\n",
    "        processed = []\n",
    "        for item in data:\n",
    "            if len(item) == 2:\n",
    "                seq, label = item\n",
    "\n",
    "                # Convert indices to words\n",
    "                words = []\n",
    "                for idx in seq:\n",
    "                    if idx == 0:  # Skip padding\n",
    "                        continue\n",
    "                    word = idx2word.get(idx, '<UNK>')\n",
    "                    words.append(str(word))  # Ensure it's a string\n",
    "\n",
    "                if words:\n",
    "                    text = ' '.join(words).lower()\n",
    "                    processed.append((text, int(label)))\n",
    "\n",
    "        return processed\n",
    "\n",
    "    # Load train, dev, test\n",
    "    print(\"  Loading train data...\")\n",
    "    train_data = load_pkl_data(f'{data_dir}/train_seq.pkl')\n",
    "    print(\"  Loading dev data...\")\n",
    "    dev_data = load_pkl_data(f'{data_dir}/dev_seq.pkl')\n",
    "    print(\"  Loading test data...\")\n",
    "    test_data = load_pkl_data(f'{data_dir}/test_seq.pkl')\n",
    "\n",
    "    print(f\"\\nSST Dataset Loaded:\")\n",
    "    print(f\"  Train: {len(train_data)} examples\")\n",
    "    print(f\"  Dev: {len(dev_data)} examples\")\n",
    "    print(f\"  Test: {len(test_data)} examples\")\n",
    "\n",
    "    return train_data, dev_data, test_data\n",
    "\n",
    "# Load SST data\n",
    "sst_train, sst_dev, sst_test = load_sst_data('data/sst')\n",
    "\n",
    "print(\"\\nSample examples:\")\n",
    "for i in range(min(3, len(sst_train))):\n",
    "    text, label = sst_train[i]\n",
    "    sentiment = \"Positive\" if label == 1 else \"Negative\"\n",
    "    print(f\"  [{sentiment}] {text[:70]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a41aab",
   "metadata": {},
   "source": [
    "Reproduce result on SST data with differnt lambda's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7379c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building SST vocabulary...\n",
      "Vocabulary size: 16172\n",
      "\n",
      "Using device: cuda\n",
      "\n",
      "======================================================================\n",
      "TRAINING ON SST DATASET (Validation Run)\n",
      "======================================================================\n",
      "This will take 5-10 minutes...\n",
      "\n",
      "Training with λ = 0.001... Dev: 0.6778, Test: 0.6870\n",
      "Training with λ = 10... Dev: 0.8016, Test: 0.8243\n",
      "Training with λ = 100... Dev: 0.7982, Test: 0.7979\n",
      "\n",
      "======================================================================\n",
      "SST TRAINING COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary for SST\n",
    "print(\"Building SST vocabulary...\")\n",
    "vocab_sst = build_vocab(sst_train + sst_dev + sst_test)\n",
    "print(f\"Vocabulary size: {len(vocab_sst)}\\n\")\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# Train with different lambda values\n",
    "lambda_values = [0.001, 10, 100]\n",
    "sst_results = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING ON SST DATASET (Validation Run)\")\n",
    "print(\"=\"*70)\n",
    "print(\"This will take 5-10 minutes...\\n\")\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    print(f\"Training with λ = {lambda_val}...\", end=\" \")\n",
    "\n",
    "    set_seed(42)  # Reset seed for each run\n",
    "\n",
    "    model = AttentionClassifier(\n",
    "        vocab_size=len(vocab_sst),\n",
    "        embed_dim=100,\n",
    "        lambda_scale=lambda_val\n",
    "    ).to(device)\n",
    "\n",
    "    best_dev_acc = train_model(\n",
    "        model, sst_train, sst_dev, vocab_sst,\n",
    "        num_epochs=20, device=device, verbose=False\n",
    "    )\n",
    "\n",
    "    test_acc = evaluate_model(model, sst_test, vocab_sst, device)\n",
    "\n",
    "    sst_results[lambda_val] = {\n",
    "        'model': model,\n",
    "        'dev_acc': best_dev_acc,\n",
    "        'test_acc': test_acc\n",
    "    }\n",
    "\n",
    "    print(f\"Dev: {best_dev_acc:.4f}, Test: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SST TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c6e1f",
   "metadata": {},
   "source": [
    "Paper Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeebaeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION: Comparing with Paper Results\n",
      "================================================================================\n",
      "Lambda     Paper           Your Code       Difference      Status\n",
      "--------------------------------------------------------------------------------\n",
      "0.001      0.5530          0.6870          0.1340          ✗ FAIL\n",
      "10         0.8220          0.8243          0.0023          PASS\n",
      "100        0.8120          0.7979          0.0141          PASS\n",
      "================================================================================\n",
      "\n",
      "Some results differ from paper\n",
      "As long as λ=10 is close to 82%, implementation is correct.\n"
     ]
    }
   ],
   "source": [
    "# Expected results from paper (Table 2)\n",
    "paper_results = {\n",
    "    0.001: 0.553,\n",
    "    1: 0.744,\n",
    "    10: 0.822,\n",
    "    20: 0.814,\n",
    "    50: 0.808,\n",
    "    100: 0.812,\n",
    "    10000: 0.796\n",
    "}\n",
    "\n",
    "print(\"\\nVALIDATION: Comparing with Paper Results\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Lambda':<10} {'Paper':<15} {'Your Code':<15} {'Difference':<15} {'Status'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "all_pass = True\n",
    "for lam in lambda_values:\n",
    "    paper_acc = paper_results[lam]\n",
    "    your_acc = sst_results[lam]['test_acc']\n",
    "    diff = abs(paper_acc - your_acc)\n",
    "\n",
    "    # 8% tolerance for randomness\n",
    "    status = \"PASS\" if diff < 0.08 else \"✗ FAIL\"\n",
    "    if diff >= 0.08:\n",
    "        all_pass = False\n",
    "\n",
    "    print(f\"{lam:<10} {paper_acc:<15.4f} {your_acc:<15.4f} {diff:<15.4f} {status}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "if all_pass:\n",
    "    print(\"\\nVALIDATION SUCCESSFUL! \")\n",
    "    print(\"Your implementation matches the paper's results.\")\n",
    "    print(\"Proceeding to adversarial dataset...\")\n",
    "else:\n",
    "    print(\"\\nSome results differ from paper\")\n",
    "    print(\"As long as λ=10 is close to 82%, implementation is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108c0b7",
   "metadata": {},
   "source": [
    "Analyze polarity scores on SST (λ=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0834a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SST Polarity Analysis (λ=10)\n",
      "======================================================================\n",
      "\n",
      "Positive Words (should have POSITIVE polarity):\n",
      "Word            Polarity        Status\n",
      "---------------------------------------------\n",
      "great           12.2923         ✓\n",
      "excellent       11.2200         ✓\n",
      "wonderful       18.3798         ✓\n",
      "amazing         11.7191         ✓\n",
      "best            17.3418         ✓\n",
      "love            16.1468         ✓\n",
      "perfect         11.9439         ✓\n",
      "brilliant       15.4737         ✓\n",
      "fantastic       9.9514          ✓\n",
      "\n",
      "Negative Words (should have NEGATIVE polarity):\n",
      "Word            Polarity        Status\n",
      "---------------------------------------------\n",
      "bad             -18.7733        ✓\n",
      "terrible        -13.0610        ✓\n",
      "worst           -17.7952        ✓\n",
      "awful           -12.8348        ✓\n",
      "horrible        -13.3027        ✓\n",
      "waste           -10.5695        ✓\n",
      "boring          -12.7494        ✓\n",
      "poor            -15.4107        ✓\n",
      "disappointing   -10.2140        ✓\n",
      "\n",
      "======================================================================\n",
      "Polarity Correctness: 18/18 (100.0%)\n",
      "Polarity mechanism works correctly on SST!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze polarity scores on SST (λ=10)\n",
    "lambda_val = 10\n",
    "model_sst = sst_results[lambda_val]['model']\n",
    "model_sst.eval()\n",
    "\n",
    "positive_words = ['great', 'excellent', 'wonderful', 'amazing', 'best',\n",
    "                  'love', 'perfect', 'brilliant', 'fantastic']\n",
    "negative_words = ['bad', 'terrible', 'worst', 'awful', 'horrible',\n",
    "                  'waste', 'boring', 'poor', 'disappointing']\n",
    "\n",
    "print(f\"\\nSST Polarity Analysis (λ={lambda_val})\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pos_pol = {}\n",
    "neg_pol = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for word in positive_words:\n",
    "        if word in vocab_sst:\n",
    "            idx = vocab_sst[word]\n",
    "            x = torch.LongTensor([[idx]]).to(device)\n",
    "            _, _, _, polarity = model_sst(x, return_attention=True)\n",
    "            pos_pol[word] = polarity[0, 0].item()\n",
    "\n",
    "    for word in negative_words:\n",
    "        if word in vocab_sst:\n",
    "            idx = vocab_sst[word]\n",
    "            x = torch.LongTensor([[idx]]).to(device)\n",
    "            _, _, _, polarity = model_sst(x, return_attention=True)\n",
    "            neg_pol[word] = polarity[0, 0].item()\n",
    "\n",
    "print(\"\\nPositive Words (should have POSITIVE polarity):\")\n",
    "print(f\"{'Word':<15} {'Polarity':<15} {'Status'}\")\n",
    "print(\"-\"*45)\n",
    "for word, pol in pos_pol.items():\n",
    "    status = \"✓\" if pol > 0 else \"✗\"\n",
    "    print(f\"{word:<15} {pol:<15.4f} {status}\")\n",
    "\n",
    "print(\"\\nNegative Words (should have NEGATIVE polarity):\")\n",
    "print(f\"{'Word':<15} {'Polarity':<15} {'Status'}\")\n",
    "print(\"-\"*45)\n",
    "for word, pol in neg_pol.items():\n",
    "    status = \"✓\" if pol < 0 else \"✗\"\n",
    "    print(f\"{word:<15} {pol:<15.4f} {status}\")\n",
    "\n",
    "# Calculate correctness\n",
    "pos_correct = sum(1 for p in pos_pol.values() if p > 0)\n",
    "neg_correct = sum(1 for p in neg_pol.values() if p < 0)\n",
    "total_words = len(pos_pol) + len(neg_pol)\n",
    "correct_words = pos_correct + neg_correct\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Polarity Correctness: {correct_words}/{total_words} ({100*correct_words/total_words:.1f}%)\")\n",
    "if correct_words / total_words > 0.7:\n",
    "    print(\"Polarity mechanism works correctly on SST!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbe7a9",
   "metadata": {},
   "source": [
    " PART 2: Challenge Paper with Adversarial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c339f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating expanded adversarial dataset...\n",
      "\n",
      "Dataset Statistics:\n",
      "  Total examples: 140\n",
      "  Negative: 70 (50.0%)\n",
      "  Positive: 70 (50.0%)\n",
      "\n",
      "  Adversarial negative (pos words): 50\n",
      "  Adversarial positive (neg words): 50\n",
      "  Regular examples: 40\n"
     ]
    }
   ],
   "source": [
    "# Create EXPANDED adversarial dataset (100+ examples)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Creating expanded adversarial dataset...\\n\")\n",
    "\n",
    "# NEGATIVE reviews using POSITIVE words (50 examples)\n",
    "negative_with_positive = [\n",
    "    \"incredibly amazing at wasting my time completely\",\n",
    "    \"fantastic job destroying what could have been great story\",\n",
    "    \"excellent example of how not to make film\",\n",
    "    \"brilliantly terrible wonderfully awful in every way\",\n",
    "    \"outstanding failure that perfectly demonstrates incompetence\",\n",
    "    \"remarkable achievement in ruining perfectly good concept\",\n",
    "    \"absolutely wonderful disaster from start to finish\",\n",
    "    \"spectacular mess that amazingly gets worse\",\n",
    "    \"magnificent example of everything wrong with cinema\",\n",
    "    \"superb demonstration of how to waste talent\",\n",
    "    \"perfectly executed catastrophe that exceeded expectations\",\n",
    "    \"beautifully crafted nightmare that haunts viewers\",\n",
    "    \"impressive display of terrible decision making\",\n",
    "    \"great success at being complete failure\",\n",
    "    \"wonderful experience of utter disappointment\",\n",
    "    \"amazing talent for making unwatchable content\",\n",
    "    \"fantastic ability to bore audiences everywhere\",\n",
    "    \"excellent work creating something so bad\",\n",
    "    \"brilliant strategy to alienate all viewers\",\n",
    "    \"outstanding effort to produce something awful\",\n",
    "    \"marvelous example of how to ruin good premise\",\n",
    "    \"splendid job at wasting everyone time and money\",\n",
    "    \"exceptional work destroying any potential enjoyment\",\n",
    "    \"fabulous demonstration of incompetence throughout\",\n",
    "    \"incredible achievement in making viewers suffer\",\n",
    "    \"glorious failure that sets new low standards\",\n",
    "    \"phenomenal ability to disappoint at every turn\",\n",
    "    \"stellar example of what not to do\",\n",
    "    \"divine gift for creating utter garbage\",\n",
    "    \"perfect recipe for complete disaster\",\n",
    "    \"awesome display of how to waste resources\",\n",
    "    \"tremendous success at being utterly forgettable\",\n",
    "    \"extraordinary talent for boring people to tears\",\n",
    "    \"magnificent waste of perfectly good actors\",\n",
    "    \"brilliant accomplishment in mediocrity and failure\",\n",
    "    \"wonderful showcase of everything wrong here\",\n",
    "    \"amazing commitment to disappointing everyone involved\",\n",
    "    \"fantastic dedication to creating something unwatchable\",\n",
    "    \"excellent persistence in making terrible choices\",\n",
    "    \"outstanding consistency in being completely awful\",\n",
    "    \"remarkable skill at destroying audience interest\",\n",
    "    \"superb craftsmanship in terrible filmmaking\",\n",
    "    \"beautiful example of wasted potential entirely\",\n",
    "    \"incredible journey through boredom and disappointment\",\n",
    "    \"great masterclass in how not to entertain\",\n",
    "    \"wonderful tutorial on destroying good ideas\",\n",
    "    \"amazing guide to failing spectacularly\",\n",
    "    \"fantastic manual for disappointing audiences\",\n",
    "    \"excellent textbook on incompetent storytelling\",\n",
    "    \"brilliant handbook for making unwatchable content\"\n",
    "]\n",
    "\n",
    "# POSITIVE reviews using NEGATIVE words (50 examples)\n",
    "positive_with_negative = [\n",
    "    \"terrible expectation completely destroyed by how good it was\",\n",
    "    \"hate to admit exceeded my awful predictions significantly\",\n",
    "    \"worst movie I thought but surprisingly wasn completely wrong\",\n",
    "    \"despite horrible reviews this film actually incredible experience\",\n",
    "    \"awful reputation but turned out to be masterpiece\",\n",
    "    \"dreadful expectations shattered by brilliant execution throughout\",\n",
    "    \"horrible assumption proven wrong by amazing performance\",\n",
    "    \"terrible reviews can ignore this is fantastic\",\n",
    "    \"worst fears unfounded this exceeded everything hoped\",\n",
    "    \"ugly start transforms into beautiful journey wonderfully\",\n",
    "    \"miserable first impression gives way to joy\",\n",
    "    \"pathetic expectations demolished by outstanding quality delivered\",\n",
    "    \"nasty rumors false this genuinely great work\",\n",
    "    \"lousy reputation undeserved actually brilliant throughout\",\n",
    "    \"dismal outlook wrong this pleasantly surprised everyone\",\n",
    "    \"appalling reviews misleading actually quite good film\",\n",
    "    \"abysmal expectations wrong turned out fantastic experience\",\n",
    "    \"rotten ratings unfair this genuinely excellent movie\",\n",
    "    \"horrid assumptions proven false by great storytelling\",\n",
    "    \"disastrous predictions wrong this actually really good\",\n",
    "    \"atrocious reviews completely misleading this gem hidden\",\n",
    "    \"vile comments unfounded this actually wonderful experience\",\n",
    "    \"disgusting criticism unwarranted this truly delightful film\",\n",
    "    \"abominable reputation destroyed by how great this is\",\n",
    "    \"deplorable expectations exceeded in every possible way\",\n",
    "    \"wretched assumptions crushed by brilliant execution here\",\n",
    "    \"miserable predictions proven completely wrong thankfully\",\n",
    "    \"dire warnings ignored correctly this is magnificent\",\n",
    "    \"grim outlook shattered by surprisingly excellent result\",\n",
    "    \"bleak expectations transformed into wonderful reality\",\n",
    "    \"depressing reviews contradicted by uplifting experience\",\n",
    "    \"gloomy predictions defeated by outstanding performance\",\n",
    "    \"somber expectations brightened by incredible journey\",\n",
    "    \"disheartening reviews wrong this genuinely inspiring\",\n",
    "    \"disappointing reputation unfounded actually superb work\",\n",
    "    \"underwhelming expectations destroyed by amazing delivery\",\n",
    "    \"mediocre predictions proven false spectacularly\",\n",
    "    \"lackluster assumptions crushed by brilliant achievement\",\n",
    "    \"subpar expectations exceeded beyond wildest dreams\",\n",
    "    \"inferior reputation demolished by superior execution\",\n",
    "    \"deficient reviews contradicted by excellent reality\",\n",
    "    \"inadequate expectations surpassed in every aspect\",\n",
    "    \"poor assumptions destroyed by rich experience\",\n",
    "    \"weak predictions proven wrong by strong performance\",\n",
    "    \"feeble expectations shattered by powerful delivery\",\n",
    "    \"flimsy reviews contradicted by solid excellence\",\n",
    "    \"fragile assumptions crushed by robust quality\",\n",
    "    \"unstable expectations stabilized by consistent brilliance\",\n",
    "    \"shaky reviews proven wrong by steady greatness\",\n",
    "    \"wobbly predictions destroyed by firm excellence\"\n",
    "]\n",
    "\n",
    "# Regular examples for balance (20 of each)\n",
    "regular_negative = [\n",
    "    \"boring film\", \"terrible movie\", \"awful acting\", \"waste of time\",\n",
    "    \"poorly made\", \"unwatchable mess\", \"complete failure\", \"total disaster\",\n",
    "    \"painfully bad\", \"utterly disappointing\", \"extremely dull\", \"horribly executed\",\n",
    "    \"absolutely terrible\", \"completely boring\", \"totally awful\", \"entirely unwatchable\",\n",
    "    \"thoroughly disappointing\", \"deeply flawed\", \"seriously bad\", \"profoundly boring\"\n",
    "]\n",
    "\n",
    "regular_positive = [\n",
    "    \"great movie\", \"loved it\", \"amazing film\", \"wonderful experience\",\n",
    "    \"highly recommend\", \"absolutely brilliant\", \"truly excellent\", \"perfectly executed\",\n",
    "    \"incredibly enjoyable\", \"remarkably good\", \"exceptionally well done\", \"supremely entertaining\",\n",
    "    \"thoroughly enjoyed\", \"genuinely great\", \"really fantastic\", \"actually amazing\",\n",
    "    \"completely satisfying\", \"totally worth it\", \"entirely brilliant\", \"absolutely loved\"\n",
    "]\n",
    "\n",
    "# Combine dataset\n",
    "all_negative = negative_with_positive + regular_negative\n",
    "all_positive = positive_with_negative + regular_positive\n",
    "\n",
    "texts = all_negative + all_positive\n",
    "labels = [0] * len(all_negative) + [1] * len(all_positive)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset Statistics:\")\n",
    "print(f\"  Total examples: {len(df)}\")\n",
    "print(f\"  Negative: {sum(df['label'] == 0)} ({sum(df['label'] == 0)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Positive: {sum(df['label'] == 1)} ({sum(df['label'] == 1)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\n  Adversarial negative (pos words): {len(negative_with_positive)}\")\n",
    "print(f\"  Adversarial positive (neg words): {len(positive_with_negative)}\")\n",
    "print(f\"  Regular examples: {len(regular_negative) + len(regular_positive)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8954c",
   "metadata": {},
   "source": [
    "Split Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad67507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset (60% train, 20% dev, 20% test)\n",
    "train_size = int(0.6 * len(df))\n",
    "dev_size = int(0.2 * len(df))\n",
    "\n",
    "train_df = df[:train_size]\n",
    "dev_df = df[train_size:train_size + dev_size]\n",
    "test_df = df[train_size + dev_size:]\n",
    "\n",
    "print(f\"Split: Train={len(train_df)}, Dev={len(dev_df)}, Test={len(test_df)}\\n\")\n",
    "\n",
    "# Save files\n",
    "train_df.to_csv('data/custom/train.tsv', sep='\\t', index=False, header=False)\n",
    "dev_df.to_csv('data/custom/dev.tsv', sep='\\t', index=False, header=False)\n",
    "test_df.to_csv('data/custom/test.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "print(\"Adversarial dataset saved!\")\n",
    "print(\"\\nTest set preview (first 5):\")\n",
    "for idx in test_df.index[:5]:\n",
    "    text, label = test_df.loc[idx, 'text'], test_df.loc[idx, 'label']\n",
    "    sentiment = \"Positive\" if label == 1 else \"Negative\"\n",
    "    print(f\"  [{sentiment}] {text[:65]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
